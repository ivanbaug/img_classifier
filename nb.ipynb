{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings.config import log_config, db_file, IMAGE_FOLDER, SESSION_OUTPUT_FOLDER\n",
    "import db.db_funcs as dbf\n",
    "images_dir = os.listdir(IMAGE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "with dbf.db_ops(db_file) as cursor:\n",
    "    session_id = 2\n",
    "    cursor.execute(\"select name as filename, classification from image where session_id = ? and classification != '';\", (session_id,))\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    for row in rows:\n",
    "        data_list.append({'filename': IMAGE_FOLDER+'/'+row[0], 'class': row[1]})\n",
    "    print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract unique classes and map them to integers\n",
    "class_names = sorted(set(item[\"class\"] for item in data_list))\n",
    "number_of_classes = len(class_names)\n",
    "map_label_to_index = {label: index for index, label in enumerate(class_names)}\n",
    "map_index_to_label = {index: label for label, index in map_label_to_index.items()}\n",
    "map_label_to_categorical = {label: tf.keras.utils.to_categorical(index, num_classes=len(class_names)) for index, label in map_index_to_label.items()}\n",
    "print(map_label_to_categorical)\n",
    "\n",
    "for item in data_list:\n",
    "    item[\"label\"] = map_label_to_categorical[item[\"class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess each image\n",
    "def load_image(filename, label):\n",
    "\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_image(image, channels=3, expand_animations = False)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    return image, label\n",
    "\n",
    "def create_dataset(data_list):\n",
    "    filenames = [item['filename'] for item in data_list]\n",
    "    # print(filenames)\n",
    "    labels = [item['label'] for item in data_list]\n",
    "    \n",
    "    # Create a dataset from the filenames and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    \n",
    "    # Map the process_image function to each element\n",
    "    dataset = dataset.map(load_image)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "dataset = create_dataset(data_list)\n",
    "\n",
    "# # Batch the dataset\n",
    "batch_size = 32\n",
    "dataset = dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.element_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1]\n",
    "# 0 screenshots\n",
    "# 1 keep\n",
    "# 2 work\n",
    "# 100 screenshots\n",
    "# 010 keep\n",
    "# 001 work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=5, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:5]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "dataset = dataset.map(lambda x, y: (x / 255.0, y))\n",
    "scaled_iterator = dataset.as_numpy_iterator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=5, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:5]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "test_size = int(0.1 * len(dataset)) or 1\n",
    "val_size = int(0.2 * len(dataset)) or 1\n",
    "train_size = len(dataset) - test_size - val_size\n",
    "print(train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(train_size)\n",
    "val = dataset.skip(train_size).take(val_size)\n",
    "test = dataset.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size (batch[0].shape) of the image 256x256 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Dense(number_of_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(train_generator, epochs=25, steps_per_epoch=20, validation_data = validation_generator, verbose = 1, validation_steps=3)\n",
    "steps_per_epoch = len(train)//train_size\n",
    "validation_steps = len(val)//val_size\n",
    "print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "print(f\"validation_steps: {validation_steps}\")\n",
    "\n",
    "history = model.fit(train, epochs=25, validation_data = val, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
    "pre = Precision()\n",
    "rec = Recall()\n",
    "cat_acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    rec.update_state(y, yhat)\n",
    "    cat_acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision: {pre.result().numpy()}\")\n",
    "print(f\"Recall: {rec.result().numpy()}\")\n",
    "print(f\"Categorical Accuracy: {cat_acc.result().numpy()}\")\n",
    "\n",
    "# 100 screenshots\n",
    "# 010 keep\n",
    "# 001 work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './tmp/both/ssh.jpg'\n",
    "# img_path = './tmp/both/wrk.jpg'\n",
    "# img_path = './tmp/both/kp.jpg'\n",
    "img = mpimg.imread(img_path)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "resize = tf.image.resize(img, [256, 256])\n",
    "yhat = model.predict(np.expand_dims(resize/255.0, 0))\n",
    "print(yhat)\n",
    "# get index of max value in array\n",
    "pred = np.argmax(yhat)\n",
    "if pred == 0:\n",
    "    print(\"screenshot\")\n",
    "elif pred == 1:\n",
    "    print(\"keep\")\n",
    "else:\n",
    "    print(\"work\")\n",
    "# 100 screenshots\n",
    "# 010 keep\n",
    "# 001 work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, [256, 256])\n",
    "yhat = model.predict(np.expand_dims(resize/255.0, 0))\n",
    "# get index of max value in array\n",
    "pred = np.argmax(yhat)\n",
    "if pred == 0:\n",
    "    print(\"screenshot\")\n",
    "elif pred == 1:\n",
    "    print(\"keep\")\n",
    "else:\n",
    "    print(\"work\")\n",
    "# 100 screenshots\n",
    "# 010 keep\n",
    "# 001 work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of max value in array\n",
    "pred = np.argmax(yhat)\n",
    "if pred == 0:\n",
    "    print(\"screenshot\")\n",
    "elif pred == 1:\n",
    "    print(\"keep\")\n",
    "else:\n",
    "    print(\"work\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
